{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joanachoong/Externship/blob/main/theme_categorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f4318f",
      "metadata": {
        "id": "b2f4318f"
      },
      "source": [
        "# Theme Categorization Notebook\n",
        "\n",
        "This notebook contains the **full code and explanations** used to categorize Glassdoor reviews and YouTube transcripts into topic themes. It:\n",
        "\n",
        "- Loads the combined CSV `glassdoor_and_youtube_sentiment.csv` (created earlier).\n",
        "- Defines a detailed `theme_keywords` dictionary with multi-word phrases and keywords for each theme.\n",
        "- Provides utility functions for text normalization and theme matching.\n",
        "- Categorizes **Glassdoor** fields: `cleaned_summary`, `cleaned_reviewPros`, `cleaned_reviewCons` (adds per-field and combined theme columns).\n",
        "- Categorizes **YouTube** field: `transcript_cleaned` (adds `categorized_transcript` and updates `categorized_combined`).\n",
        "- Offers options to increase precision (require multiple keyword hits), produce one-hot columns for top themes, and save outputs.\n",
        "\n",
        "> Notes:\n",
        "- Matching is case-insensitive and prefers phrase matches (e.g., \"conveyor belt\") before single-word matches.\n",
        "- The notebook is self-contained and runnable in a standard Python environment with `pandas` installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c56728",
      "metadata": {
        "id": "51c56728"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import re\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# Adjust display options for nicer notebook outputs\n",
        "pd.options.display.max_colwidth = 200\n",
        "pd.options.display.max_rows = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac5c3f5",
      "metadata": {
        "id": "5ac5c3f5"
      },
      "outputs": [],
      "source": [
        "# Load the combined CSV file (make sure the path is correct)\n",
        "input_path = '/mnt/data/glassdoor_and_youtube_sentiment.csv'\n",
        "try:\n",
        "    df = pd.read_csv(input_path)\n",
        "    print('Loaded', len(df), 'rows from', input_path)\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Could not find {input_path}. Make sure the combined CSV exists.\")\n",
        "\n",
        "# Quick peek\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f626b4d3",
      "metadata": {
        "id": "f626b4d3"
      },
      "outputs": [],
      "source": [
        "# Detailed theme_keywords dictionary\n",
        "# (Expanded with many phrases and variants â€” you can tune this list)\n",
        "theme_keywords = {\n",
        "    \"High-Velocity Physical Strain & Injury Risk\": [\n",
        "        \"conveyor belt\", \"conveyor\", \"belt never stops\", \"pace\", \"high pace\", \"quota\", \"athletic\",\n",
        "        \"lift\", \"lifting\", \"heavy lifting\", \"bending\", \"standing all day\", \"standing on concrete\",\n",
        "        \"walking miles\", \"repetitive\", \"repetitive motion\", \"back pain\", \"shoulder pain\", \"knee pain\",\n",
        "        \"wrist pain\", \"body breakdown\", \"fatigue\", \"exhaustion from work\", \"energy drink\", \"redbull\",\n",
        "        \"cramps\", \"physically draining\", \"strained\", \"hurt on the job\", \"injury\", \"hurt\", \"sprain\", \"strain\",\n",
        "        \"long-term body damage\", \"osha\", \"injury rate\"\n",
        "    ],\n",
        "\n",
        "    \"Surveillance-Driven Micromanagement\": [\n",
        "        \"time off task\", \"tot\", \"written up\", \"written warning\", \"tracked\", \"monitor\", \"monitoring\",\n",
        "        \"surveil\", \"camera\", \"cameras\", \"algorithmic\", \"algorithm\", \"metrics\", \"score\", \"rate\",\n",
        "        \"productivity target\", \"upt\", \"u p t\", \"scored\", \"scanning\", \"scanned\", \"badge scan\",\n",
        "        \"tracking every second\", \"micro-manage\", \"micromanage\", \"micromanaged\", \"policing\", \"policed\",\n",
        "        \"policed bathroom\", \"bathroom break\", \"scrutiny\", \"logged\"\n",
        "    ],\n",
        "\n",
        "    \"Operational Inflexibility & Burnout\": [\n",
        "        \"mandatory overtime\", \"met\", \"10 hour\", \"12 hour\", \"10-12 hours\", \"overtime\", \"forced overtime\",\n",
        "        \"unpredictable schedule\", \"schedule change\", \"shift swap\", \"point system\", \"attendance points\",\n",
        "        \"attendance policy\", \"no flexibility\", \"no time for family\", \"work-life balance\", \"too tired for life\",\n",
        "        \"burnout\", \"exhausted after shift\", \"no recovery time\", \"cannot take leave\", \"pto denied\", \"unpaid time off\",\n",
        "        \"upt\", \"unpaid\"\n",
        "    ],\n",
        "\n",
        "    \"Rigid Pay Structure & Caps\": [\n",
        "        \"step plan\", \"step increase\", \"three year cap\", \"pay cap\", \"no raises\", \"incremental raise\",\n",
        "        \"stuck at\", \"pay freeze\", \"wage cap\", \"hourly cap\", \"no merit\", \"pay plateau\", \"raise denied\",\n",
        "        \"salary cap\", \"compensation structure\", \"comp plan\"\n",
        "    ],\n",
        "\n",
        "    \"Temporary vs. Long-Term Career\": [\n",
        "        \"seasonal\", \"temporary\", \"temp\", \"contract\", \"one year\", \"two years\", \"short-term\", \"stepping stone\",\n",
        "        \"no career\", \"no future\", \"retention\", \"turnover\", \"quit after season\"\n",
        "    ],\n",
        "\n",
        "    \"PA Advancement / Promotion Bottleneck\": [\n",
        "        \"process assistant\", \"pa role\", \"promotion to pa\", \"promotion criteria\", \"hard to get promoted\",\n",
        "        \"promotion blocked\", \"no clear path\", \"promotion unfair\", \"seniority only\"\n",
        "    ],\n",
        "\n",
        "    \"Safety & Injury Reporting\": [\n",
        "        \"osha\", \"reporting\", \"incident report\", \"near miss\", \"ppe\", \"safety training\", \"no ppe\", \"unsafe\",\n",
        "        \"hazard\", \"unsafe equipment\", \"not reported\", \"cover up\", \"safety walk\", \"safety protocol\",\n",
        "        \"slip\", \"trip\", \"fall\"\n",
        "    ],\n",
        "\n",
        "    \"Compensation & Benefits\": [\n",
        "        \"pay\", \"wage\", \"salary\", \"starting salary\", \"competitive pay\", \"benefits\", \"healthcare\", \"medical\",\n",
        "        \"401k\", \"retirement\", \"vacation\", \"paid time off\", \"day 1 benefits\", \"insurance\", \"bonus\",\n",
        "        \"holiday pay\", \"sick pay\"\n",
        "    ],\n",
        "\n",
        "    \"Training Gaps\": [\n",
        "        \"training\", \"onboarding\", \"no onboarding\", \"no training\", \"we had to train each other\", \"no support\",\n",
        "        \"confused\", \"learn on the job\", \"left alone\", \"no mentor\", \"cross-training\", \"no assigned trainer\",\n",
        "        \"no one assigned to us\", \"first day invisible\", \"felt invisible\", \"no orientation\"\n",
        "    ],\n",
        "\n",
        "    \"Scheduling Issues\": [\n",
        "        \"shift\", \"hours\", \"schedule\", \"night shift\", \"weekend\", \"shift swap\", \"prefered schedule denied\",\n",
        "        \"schedule posted late\", \"short notice\", \"last minute\", \"unpredictable\", \"rota\", \"roster\", \"on-call\",\n",
        "        \"shift cancellation\"\n",
        "    ],\n",
        "\n",
        "    \"Work Conditions (Physical)\": [\n",
        "        \"cold warehouse\", \"hot floor\", \"no ventilation\", \"no chairs\", \"concrete floors\", \"wet floor\", \"dirty\",\n",
        "        \"smelly\", \"lighting\", \"noise\", \"broken equipment\", \"standing\", \"no break area\", \"broken restroom\",\n",
        "        \"bathroom conditions\"\n",
        "    ],\n",
        "\n",
        "    \"Emotional Tone & Voice\": [\n",
        "        \"felt invisible\", \"i felt\", \"i was\", \"angry\", \"frustrated\", \"upset\", \"happy\", \"grateful\", \"appreciated\",\n",
        "        \"proud\", \"demoralized\", \"dehumanized\", \"disrespected\", \"scared\", \"afraid\", \"unsafe\", \"stress\",\n",
        "        \"stressed\", \"anxious\", \"depressed\"\n",
        "    ],\n",
        "\n",
        "    \"Management Support & Communication\": [\n",
        "        \"manager\", \"supervisor\", \"no support\", \"ignored\", \"only interacts to enforce\", \"never heard from manager\",\n",
        "        \"lack of leadership\", \"feedback never given\", \"no recognition\", \"sends emails only\", \"communication breakdown\",\n",
        "        \"questions ignored\", \"escalation ignored\"\n",
        "    ],\n",
        "\n",
        "    \"Praise & Positive Signals\": [\n",
        "        \"good pay\", \"solid option\", \"clean working environment\", \"day 1 benefits\", \"helpful teammates\",\n",
        "        \"teamwork\", \"learned a lot\", \"fast promotion\", \"flexible manager\", \"great benefits\", \"positive\",\n",
        "        \"recommend\", \"satisfied\", \"enjoyed\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Lowercase all keywords for reliable matching\n",
        "for k in theme_keywords:\n",
        "    theme_keywords[k] = list(dict.fromkeys([kw.lower() for kw in theme_keywords[k]]))\n",
        "\n",
        "# Show the theme list summary\n",
        "print('Loaded', len(theme_keywords), 'themes. Example theme keys:')\n",
        "list(theme_keywords.keys())[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ad45c8",
      "metadata": {
        "id": "a5ad45c8"
      },
      "outputs": [],
      "source": [
        "# Helper functions for text normalization and theme matching\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Lowercase and normalize whitespace/punctuation for simpler matching.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    txt = text.lower()\n",
        "    # Normalize whitespace\n",
        "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
        "    return txt\n",
        "\n",
        "\n",
        "def find_themes(text, keywords_map, require_hits=1):\n",
        "    \"\"\"Return list of themes that match text.\n",
        "\n",
        "    - require_hits: minimum number of keyword hits required per theme to consider it matched.\n",
        "      (Default 1 = any single keyword triggers the theme.)\n",
        "    \"\"\"\n",
        "    txt = normalize_text(text)\n",
        "    if txt == \"\":\n",
        "        return []\n",
        "\n",
        "    theme_matches = []\n",
        "    for theme, keywords in keywords_map.items():\n",
        "        hit_count = 0\n",
        "        # Prioritize multi-word phrases by checking longer keywords first\n",
        "        for kw in sorted(keywords, key=lambda x: -len(x)):\n",
        "            # Word-boundary pattern for single-word keywords; phrase substring allowed\n",
        "            if ' ' in kw:\n",
        "                if kw in txt:\n",
        "                    hit_count += 1\n",
        "            else:\n",
        "                # match whole word\n",
        "                if re.search(r'\\b' + re.escape(kw) + r'\\b', txt):\n",
        "                    hit_count += 1\n",
        "            if hit_count >= require_hits:\n",
        "                theme_matches.append(theme)\n",
        "                break\n",
        "    return theme_matches\n",
        "\n",
        "# Simple test\n",
        "print(find_themes('I was exhausted after 12-hour shifts and had back pain from lifting boxes', theme_keywords))\n",
        "print(find_themes('No onboarding or training; we had to train each other', theme_keywords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f79c9c7",
      "metadata": {
        "id": "7f79c9c7"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "# set require_hits to 1 for permissive matching, increase to 2 for higher precision\n",
        "REQUIRE_HITS = 1\n",
        "\n",
        "# Columns we will process for Glassdoor reviews\n",
        "glassdoor_summary_col = 'cleaned_summary'\n",
        "glassdoor_pros_col = 'cleaned_reviewPros'\n",
        "glassdoor_cons_col = 'cleaned_reviewCons'\n",
        "\n",
        "# Ensure columns exist\n",
        "for c in [glassdoor_summary_col, glassdoor_pros_col, glassdoor_cons_col, 'source']:\n",
        "    if c not in df.columns:\n",
        "        df[c] = ''\n",
        "\n",
        "# Identify glassdoor rows (case-insensitive)\n",
        "is_glass = df['source'].astype(str).str.lower() == 'glassdoor'\n",
        "print('Glassdoor rows:', is_glass.sum())\n",
        "\n",
        "# Apply theme matching per field\n",
        "for col, out_col in [(glassdoor_summary_col, 'categorized_summary'),\n",
        "                     (glassdoor_pros_col, 'categorized_reviewPros'),\n",
        "                     (glassdoor_cons_col, 'categorized_reviewCons')]:\n",
        "    df[out_col] = [[] for _ in range(len(df))]\n",
        "    df.loc[is_glass, out_col] = df.loc[is_glass, col].fillna('').apply(lambda t: find_themes(t, theme_keywords, REQUIRE_HITS))\n",
        "\n",
        "# Combined per-row (union preserving order)\n",
        "def union_lists(a, b, c):\n",
        "    s = []\n",
        "    for lst in (a, b, c):\n",
        "        if isinstance(lst, list):\n",
        "            s.extend(lst)\n",
        "    return list(dict.fromkeys(s))\n",
        "\n",
        "# Create combined only for glassdoor rows\n",
        "combined_col = 'categorized_combined'\n",
        "df[combined_col] = [[] for _ in range(len(df))]\n",
        "df.loc[is_glass, combined_col] = df.loc[is_glass].apply(lambda r: union_lists(r['categorized_summary'], r['categorized_reviewPros'], r['categorized_reviewCons']), axis=1)\n",
        "\n",
        "print('Sample categorized (first 5 glassdoor rows):')\n",
        "df.loc[is_glass, ['cleaned_summary','cleaned_reviewPros','cleaned_reviewCons','categorized_combined']].head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1622d49",
      "metadata": {
        "id": "e1622d49"
      },
      "outputs": [],
      "source": [
        "# Process YouTube transcripts (transcript_cleaned)\n",
        "transcript_col = 'transcript_cleaned'\n",
        "if transcript_col not in df.columns:\n",
        "    df[transcript_col] = ''\n",
        "\n",
        "is_yt = df['source'].astype(str).str.lower() == 'youtube'\n",
        "print('YouTube rows:', is_yt.sum())\n",
        "\n",
        "# Create categorized_transcript column\n",
        "df['categorized_transcript'] = [[] for _ in range(len(df))]\n",
        "df.loc[is_yt, 'categorized_transcript'] = df.loc[is_yt, transcript_col].fillna('').apply(lambda t: find_themes(t, theme_keywords, REQUIRE_HITS))\n",
        "\n",
        "# Update categorized_combined for YouTube (union existing combined + transcript themes)\n",
        "for idx, row in df.loc[is_yt].iterrows():\n",
        "    existing = row.get('categorized_combined', [])\n",
        "    if isinstance(existing, str):\n",
        "        # try to parse as list-like string\n",
        "        try:\n",
        "            existing = eval(existing)\n",
        "            if not isinstance(existing, list):\n",
        "                existing = []\n",
        "        except Exception:\n",
        "            existing = []\n",
        "    transcript_themes = row.get('categorized_transcript', []) or []\n",
        "    union = list(dict.fromkeys((existing if isinstance(existing, list) else []) + (transcript_themes if isinstance(transcript_themes, list) else [])))\n",
        "    df.at[idx, 'categorized_combined'] = union\n",
        "\n",
        "# Show a few YouTube examples\n",
        "df.loc[is_yt, [transcript_col, 'categorized_transcript','categorized_combined']].head(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12370801",
      "metadata": {
        "id": "12370801"
      },
      "outputs": [],
      "source": [
        "# Create one-hot columns for top themes (useful for aggregation)\n",
        "# Find top N themes across all 'categorized_combined' entries\n",
        "all_themes = Counter()\n",
        "for cell in df['categorized_combined']:\n",
        "    try:\n",
        "        items = cell if isinstance(cell, list) else eval(cell) if isinstance(cell, str) and cell.startswith('[') else (cell if isinstance(cell, list) else [])\n",
        "    except Exception:\n",
        "        items = []\n",
        "    for it in items:\n",
        "        all_themes[it] += 1\n",
        "\n",
        "TOP_N = 12\n",
        "top_themes = [t for t,c in all_themes.most_common(TOP_N)]\n",
        "print('Top themes:', top_themes)\n",
        "\n",
        "# Add one-hot columns\n",
        "for theme in top_themes:\n",
        "    col_name = 'theme__' + re.sub(r'[^0-9a-zA-Z]+', '_', theme.lower()).strip('_')\n",
        "    def has_theme(cell, theme=theme):\n",
        "        try:\n",
        "            items = cell if isinstance(cell, list) else eval(cell) if isinstance(cell, str) and cell.startswith('[') else []\n",
        "        except Exception:\n",
        "            items = []\n",
        "        return int(theme in items)\n",
        "    df[col_name] = df['categorized_combined'].apply(has_theme)\n",
        "\n",
        "# Quick aggregation table\n",
        "agg = df[[c for c in df.columns if c.startswith('theme__')]].sum().sort_values(ascending=False)\n",
        "agg.head(12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba0c6fb",
      "metadata": {
        "id": "eba0c6fb"
      },
      "outputs": [],
      "source": [
        "# Save the annotated CSV\n",
        "output_path = '/mnt/data/glassdoor_and_youtube_sentiment_with_full_categories.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print('Saved annotated file to', output_path)\n",
        "\n",
        "# Show top theme counts and a sample of annotated rows\n",
        "agg_display = agg.reset_index()\n",
        "agg_display.columns = ['theme_col','count']\n",
        "agg_display.head(12)\n",
        "\n",
        "# Show sample rows for inspection (glassdoor and youtube)\n",
        "sample_glass = df[df['source'].astype(str).str.lower() == 'glassdoor'].head(6)\n",
        "sample_yt = df[df['source'].astype(str).str.lower() == 'youtube'].head(6)\n",
        "\n",
        "print('\\nSample Glassdoor rows with categories:')\n",
        "print(sample_glass[['cleaned_summary','cleaned_reviewPros','cleaned_reviewCons','categorized_combined']].to_string(index=False))\n",
        "\n",
        "print('\\nSample YouTube rows with transcript categories:')\n",
        "print(sample_yt[['transcript_cleaned','categorized_transcript','categorized_combined']].to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}